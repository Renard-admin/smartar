<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8" />
  <title>Анализатор объектов в реальном времени</title>
  <style>
    * { box-sizing: border-box; }
    body, html {
      margin: 0;
      padding: 0;
      overflow: hidden;
      background: #333;
      font-family: sans-serif;
      color: #fff;
    }
    #container {
      position: relative;
      width: 100vw;
      height: 100vh;
      background: #000;
    }
    /* При обычном режиме */
    #video, #overlay, #drawLayer {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
    }
    #video {
      transform: scaleX(-1);
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
    }
    #controls {
      position: absolute;
      bottom: 10px;
      left: 10px;
      z-index: 30;
    }
    #controls button {
      margin-right: 10px;
      padding: 8px 12px;
      background: rgba(0,0,0,0.7);
      border: none;
      border-radius: 4px;
      color: #fff;
      cursor: pointer;
      font-size: 14px;
    }
    #controls button:hover {
      background: rgba(0,0,0,0.9);
    }
    /* AR режим: контейнер делится на две части */
    .arContainer {
      display: flex;
      flex-direction: row;
      width: 100vw;
      height: 100vh;
    }
    .arView {
      flex: 1;
      position: relative;
      overflow: hidden;
    }
  </style>
</head>
<body>
  <div id="container">
    <!-- В обычном режиме – один вид -->
    <video id="video" autoplay playsinline muted></video>
    <canvas id="overlay"></canvas>
    <canvas id="drawLayer"></canvas>
    <div id="controls">
      <button id="fullscreenBtn">Полный экран</button>
      <button id="switchCameraBtn">Переключить камеру</button>
      <button id="toggleMirrorBtn">Зеркало: Вкл/Выкл</button>
      <button id="arBtn">AR</button>
    </div>
  </div>

  <!-- Подключение библиотек -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script defer src="https://unpkg.com/face-api.js@0.22.2/dist/face-api.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

  <script>
    // Если хотите получать перевод онлайн, установите эту переменную в true.
    const useOnlineTranslation = false;

    async function translateLabel(word) {
      try {
        const response = await fetch("https://libretranslate.de/translate", {
          method: "POST",
          body: JSON.stringify({
            q: word,
            source: "en",
            target: "ru",
            format: "text"
          }),
          headers: { "Content-Type": "application/json" }
        });
        const data = await response.json();
        return data.translatedText || word;
      } catch (err) {
        console.error("Ошибка перевода:", err);
        return word;
      }
    }

    // Элементы интерфейса
    const video = document.getElementById('video');
    const overlayCanvas = document.getElementById('overlay');
    const overlayCtx = overlayCanvas.getContext('2d');
    const drawCanvas = document.getElementById('drawLayer');
    const drawCtx = drawCanvas.getContext('2d');
    const fullscreenBtn = document.getElementById('fullscreenBtn');
    const switchCameraBtn = document.getElementById('switchCameraBtn');
    const toggleMirrorBtn = document.getElementById('toggleMirrorBtn');
    const arBtn = document.getElementById('arBtn');
    const container = document.getElementById('container');

    // Глобальные переменные
    let currentFacingMode = "user"; // "user" или "environment"
    let stream = null;
    let mirrorMode = true;
    let lastHandBox = null;
    let arMode = false;
    let originalInnerHTML = container.innerHTML; // для возврата из AR режима

    // Переменные для жестов рук
    let fistCount = 0;
    let gestureActive = false;
    let lastFistState = false;
    let lastTimeFist = 0;
    let lastDrawPoint = null;

    // Словари перевода, опасных и съедобных объектов, эмоций – оставлены без изменений
    const labelTranslations = { /* ... ваш словарь ... */ };
    const dangerousObjects = ['knife', 'pistol', 'scissors'];
    const foodObjects = ['apple', 'banana', 'pizza', 'orange', 'sandwich'];
    const emotionTranslations = {
      neutral: 'нейтральный',
      happy: 'счастлив',
      sad: 'грустен',
      angry: 'злой',
      fearful: 'испуган',
      disgusted: 'отвращение',
      surprised: 'удивлён'
    };

    // --- Кнопки управления ---
    fullscreenBtn.addEventListener('click', () => {
      if (document.fullscreenElement) {
        document.exitFullscreen();
      } else {
        container.requestFullscreen();
      }
    });
    switchCameraBtn.addEventListener('click', () => {
      currentFacingMode = (currentFacingMode === "user") ? "environment" : "user";
      initCamera(currentFacingMode);
    });
    toggleMirrorBtn.addEventListener('click', () => {
      mirrorMode = !mirrorMode;
      video.style.transform = mirrorMode ? 'scaleX(-1)' : 'scaleX(1)';
    });
    arBtn.addEventListener('click', toggleARMode);
    container.addEventListener('click', () => {
      if (!document.fullscreenElement) {
        container.requestFullscreen();
      }
    });

    // --- Инициализация камеры (запрос разрешения) ---
    async function initCamera(facingMode = "user") {
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
      }
      try {
        stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: { exact: facingMode } },
          audio: false
        });
      } catch (error) {
        stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode },
          audio: false
        });
      }
      // Если не в AR режиме, назначаем поток основному видео
      if (!arMode) {
        video.srcObject = stream;
        video.onloadedmetadata = () => {
          video.play();
          resizeCanvases();
        };
      }
    }

    // --- Подгон размеров canvas ---
    function resizeCanvases() {
      if (!arMode) {
        overlayCanvas.width = video.videoWidth || window.innerWidth;
        overlayCanvas.height = video.videoHeight || window.innerHeight;
        drawCanvas.width = overlayCanvas.width;
        drawCanvas.height = overlayCanvas.height;
      }
    }
    window.addEventListener('resize', resizeCanvases);

    // --- Функции определения состояния пальцев (без изменений) ---
    function isFingerExtended(landmarks, pipIdx, tipIdx) {
      const pip = landmarks[pipIdx];
      const tip = landmarks[tipIdx];
      const wrist = landmarks[0];
      const distTip = Math.hypot(tip.x - wrist.x, tip.y - wrist.y);
      const distPip = Math.hypot(pip.x - wrist.x, pip.y - wrist.y);
      return distTip > distPip * 1.3;
    }
    function isFist(landmarks) {
      const fingers = [
        { pip: 6, tip: 8 },
        { pip: 10, tip: 12 },
        { pip: 14, tip: 16 },
        { pip: 18, tip: 20 }
      ];
      const thumbExtended = isFingerExtended(landmarks, 2, 4);
      const othersFolded = fingers.every(f => !isFingerExtended(landmarks, f.pip, f.tip));
      return (!thumbExtended) && othersFolded;
    }
    function isIndexPointing(landmarks) {
      const indexExtended = isFingerExtended(landmarks, 6, 8);
      const otherFingers = [
        { pip: 10, tip: 12 },
        { pip: 14, tip: 16 },
        { pip: 18, tip: 20 }
      ];
      const othersFolded = otherFingers.every(f => !isFingerExtended(landmarks, f.pip, f.tip));
      return indexExtended && othersFolded;
    }
    function isOkGesture(landmarks) {
      const thumbTip = landmarks[4];
      const indexTip = landmarks[8];
      const dx = thumbTip.x - indexTip.x;
      const dy = thumbTip.y - indexTip.y;
      const dist = Math.hypot(dx, dy);
      return dist < 0.05;
    }

    // --- Функция вычисления IoU прямоугольников ---
    function computeIoU(boxA, boxB) {
      const xA = Math.max(boxA.x, boxB.x);
      const yA = Math.max(boxA.y, boxB.y);
      const xB = Math.min(boxA.x + boxA.w, boxB.x + boxB.w);
      const yB = Math.min(boxA.y + boxA.h, boxB.y + boxB.h);
      const interArea = Math.max(0, xB - xA) * Math.max(0, yB - yA);
      const boxAArea = boxA.w * boxA.h;
      const boxBArea = boxB.w * boxB.h;
      return interArea / (boxAArea + boxBArea - interArea);
    }

    // --- Инициализация Mediapipe Hands ---
    let hands = new Hands({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
    });
    hands.setOptions({
      maxNumHands: 1,
      modelComplexity: 1,
      minDetectionConfidence: 0.7,
      minTrackingConfidence: 0.7
    });
    hands.onResults(onHandsResults);

    const cameraUtils = new Camera(video, {
      onFrame: async () => { await hands.send({ image: video }); },
      width: 640,
      height: 480
    });
    cameraUtils.start();

    // --- Обработка результатов от Mediapipe Hands ---
    function onHandsResults(results) {
      if (!overlayCanvas.width || !overlayCanvas.height) {
        resizeCanvases();
      }
      overlayCtx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);
      const mirrorX = (x, width) => mirrorMode ? overlayCanvas.width - x - width : x;
      
      if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
        const landmarks = results.multiHandLandmarks[0];
        let minX = 1, minY = 1, maxX = 0, maxY = 0;
        landmarks.forEach(pt => {
          if (pt.x < minX) minX = pt.x;
          if (pt.y < minY) minY = pt.y;
          if (pt.x > maxX) maxX = pt.x;
          if (pt.y > maxY) maxY = pt.y;
        });
        const boxX = minX * overlayCanvas.width;
        const boxY = minY * overlayCanvas.height;
        const boxW = (maxX - minX) * overlayCanvas.width;
        const boxH = (maxY - minY) * overlayCanvas.height;
        overlayCtx.strokeStyle = 'lime';
        overlayCtx.lineWidth = 3;
        const adjX = mirrorX(boxX, boxW);
        overlayCtx.strokeRect(adjX, boxY, boxW, boxH);
        lastHandBox = { x: adjX, y: boxY, w: boxW, h: boxH };

        const now = Date.now();
        if (now - lastTimeFist > 700) {
          const fist = isFist(landmarks);
          if (fist !== lastFistState) {
            lastFistState = fist;
            lastTimeFist = now;
            if (fist) {
              fistCount++;
              console.log("Кулак обнаружен, счёт:", fistCount);
            }
          }
        }
        if (!gestureActive && fistCount >= 2 && isIndexPointing(landmarks)) {
          gestureActive = true;
          console.log("Режим рисования активирован");
          lastDrawPoint = null;
        }
        if (gestureActive) {
          const indexTip = landmarks[8];
          const x = (mirrorMode ? (1 - indexTip.x) : indexTip.x) * drawCanvas.width;
          const y = indexTip.y * drawCanvas.height;
          if (!lastDrawPoint) {
            lastDrawPoint = { x, y };
          } else {
            drawCtx.strokeStyle = 'black';
            drawCtx.lineWidth = 4;
            drawCtx.lineCap = 'round';
            drawCtx.beginPath();
            drawCtx.moveTo(lastDrawPoint.x, lastDrawPoint.y);
            drawCtx.lineTo(x, y);
            drawCtx.stroke();
            lastDrawPoint = { x, y };
          }
        }
        if (gestureActive && isOkGesture(landmarks)) {
          console.log("Жест OK обнаружен, очистка рисунка");
          drawCtx.clearRect(0, 0, drawCanvas.width, drawCanvas.height);
          gestureActive = false;
          fistCount = 0;
          lastDrawPoint = null;
        }
      } else {
        lastHandBox = null;
      }
    }

    // --- Распознавание лиц с face-api.js ---
    let faceModelsLoaded = false;
    let faceDetectionOptions;
    async function initFaceApi() {
      const MODEL_URL = '/models';
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
        faceapi.nets.ageGenderNet.loadFromUri(MODEL_URL),
        faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL)
      ]);
      faceDetectionOptions = new faceapi.TinyFaceDetectorOptions({ inputSize: 224, scoreThreshold: 0.5 });
      faceModelsLoaded = true;
      console.log("Модели face-api загружены");
    }

    // --- Обнаружение объектов с COCO-SSD ---
    let cocoModel = null;
    async function initCoco() {
      cocoModel = await cocoSsd.load();
      console.log("Модель COCO-SSD загружена");
    }

    // --- Обработка кадров ---
    async function processFrame() {
      if (video.readyState === 4) {
        resizeCanvases();
        if (faceModelsLoaded) {
          const detections = await faceapi.detectAllFaces(video, faceDetectionOptions)
            .withAgeAndGender()
            .withFaceExpressions();
          detections.forEach(det => {
            const { x, y, width, height } = det.detection.box;
            const adjX = mirrorMode ? overlayCanvas.width - x - width : x;
            overlayCtx.strokeStyle = 'yellow';
            overlayCtx.lineWidth = 2;
            overlayCtx.strokeRect(adjX, y, width, height);
            const expressions = det.expressions;
            const dominantExp = Object.keys(expressions).reduce((a, b) => expressions[a] > expressions[b] ? a : b);
            const mood = emotionTranslations[dominantExp] || dominantExp;
            overlayCtx.fillStyle = 'yellow';
            overlayCtx.font = '16px sans-serif';
            overlayCtx.fillText(`Человек – ${mood}`, adjX, y - 5);
          });
        }
        if (cocoModel) {
          const predictions = await cocoModel.detect(video);
          predictions.forEach(async pred => {
            let [x, y, width, height] = pred.bbox;
            const adjX = mirrorMode ? overlayCanvas.width - x - width : x;
            let color = 'yellow';
            let labelPrefix = "";
            if (dangerousObjects.includes(pred.class.toLowerCase())) {
              color = 'red';
              labelPrefix = "опасный: ";
            } else if (foodObjects.includes(pred.class.toLowerCase())) {
              color = 'green';
              labelPrefix = "еда: ";
            }
            let finalLabel;
            if (useOnlineTranslation) {
              finalLabel = await translateLabel(pred.class.toLowerCase());
            } else {
              finalLabel = labelTranslations[pred.class.toLowerCase()] || pred.class;
            }
            if (pred.class.toLowerCase() === 'person' && lastHandBox) {
              const objBox = { x: adjX, y, w: width, h: height };
              const iou = computeIoU(lastHandBox, objBox);
              if (iou > 0.3) {
                finalLabel = "кисть";
              }
            }
            overlayCtx.strokeStyle = color;
            overlayCtx.lineWidth = 2;
            overlayCtx.strokeRect(adjX, y, width, height);
            overlayCtx.fillStyle = color;
            overlayCtx.font = '16px sans-serif';
            overlayCtx.fillText(labelPrefix + finalLabel, adjX, y > 20 ? y - 5 : y + 15);
          });
        }
      }
      requestAnimationFrame(processFrame);
    }

    // --- Функция переключения AR режима ---
    function toggleARMode() {
      if (!arMode) {
        arMode = true;
        // Сохраняем текущее содержимое контейнера для возврата
        originalInnerHTML = container.innerHTML;
        // Очищаем контейнер и создаём два равных блока
        container.innerHTML = "";
        container.classList.add("arContainer");

        // Функция создания одного вида (левый/правый)
        function createArView(idPrefix) {
          const view = document.createElement("div");
          view.className = "arView";
          const vid = document.createElement("video");
          vid.id = idPrefix + "Video";
          vid.autoplay = true;
          vid.playsInline = true;
          vid.muted = true;
          vid.style.width = "100%";
          vid.style.height = "100%";
          vid.style.objectFit = "cover";
          // Применяем зеркальное отображение, если включено
          vid.style.transform = mirrorMode ? 'scaleX(-1)' : 'scaleX(1)';
          vid.srcObject = stream;
          view.appendChild(vid);
          // Можно добавить канвас для оверлея, если требуется (без функционала распознавания)
          const cv = document.createElement("canvas");
          cv.id = idPrefix + "Overlay";
          cv.style.position = "absolute";
          cv.style.top = "0";
          cv.style.left = "0";
          cv.style.width = "100%";
          cv.style.height = "100%";
          view.appendChild(cv);
          return view;
        }

        const leftView = createArView("left");
        const rightView = createArView("right");
        container.appendChild(leftView);
        container.appendChild(rightView);
        // Перемещаем блок управления (он остаётся работоспособным)
        const controls = document.getElementById("controls");
        container.appendChild(controls);
      } else {
        // Выход из AR режима: возвращаем оригинальное содержимое
        arMode = false;
        container.classList.remove("arContainer");
        container.innerHTML = originalInnerHTML;
        // Переинициализируем основной видеоэлемент с потоком
        const mainVideo = document.getElementById("video");
        if(mainVideo) {
          mainVideo.srcObject = stream;
          mainVideo.onloadedmetadata = () => { mainVideo.play(); resizeCanvases(); };
        }
      }
    }

    // --- Инициализация приложения ---
    async function initApp() {
      await initCamera(currentFacingMode);
      initFaceApi().catch(err => console.error("Ошибка загрузки face-api:", err));
      initCoco().catch(err => console.error("Ошибка загрузки COCO-SSD:", err));
      processFrame();
    }

    window.addEventListener('load', initApp);
  </script>
</body>
</html>
